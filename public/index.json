[
{
	"uri": "//localhost:1313/",
	"title": "Deploy an API web application with Elastic Beanstalk and set-up CI/CD using CodePipline",
	"tags": [],
	"description": "",
	"content": "Deploy an APIs web application with Elastic Beanstalk and set-up CI/CD using CodePipline Overall In this lab, we\u0026rsquo;ll deploy a functional API application (ASP.NET 6, Swagger UI) using AWS Elastic Beanstalk, interact with AWS RDS and then set-up a pipeline for continuous integration and continuous delivery/deployment with Github and AWS CodePipeline.\n"
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.1-create-environment-ebs/",
	"title": "Create New Elastic Beanstalk Environment",
	"tags": [],
	"description": "",
	"content": "Overview Before proceeding with the setup of AWS Elastic Beanstalk, it\u0026rsquo;s essential to first configure a new environment to ensure that the deployment process runs smoothly.\nNavigate to AWS Console UI and search Elastic Beanstalk Choose New Environment In the Environment Information, fill in Environment name you want You can choose the Domain Name you want, though it is optional. Ensure that you check the availability of the domain name.\nAfter that, select the platform, platform version and branch you want to deploy, in this tutorial will use .NET 6 on Linux In the Presets, choose High avalibility. This step allows users to efficiently set up their environment based on their specific needs, whether opting for a simple single-instance setup (potentially eligible for the free tier) or a more robust high-availability configuration. In the Application Code section, you can choose either to use the sample code for a basic deployment or to upload your own code from an S3 Bucket.\n"
},
{
	"uri": "//localhost:1313/1-introduce/1.1-elasticbeanstalk/",
	"title": "Introduce to Elastic Beanstalk",
	"tags": [],
	"description": "",
	"content": "Overview Elastic Beanstalk is a fully managed service provided by Amazon Web Services (AWS) that simplifies the deployment and management of applications. It allows developers to quickly deploy and manage applications in various languages such as Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers like Apache, Nginx, Passenger, and IIS.\nWith Elastic Beanstalk, you simply upload your code, and the service automatically handles the deployment, from capacity provisioning, load balancing, and auto-scaling to application health monitoring. This frees developers from dealing with infrastructure management, letting them focus on writing code.\nElastic Beanstalk Advantage\nSimplified Deployment: Easy to deploy applications without managing infrastructure. Automatic Scaling: Automatically scales applications based on demand. Built-In Monitoring: Integrated with AWS CloudWatch for real-time health monitoring. Multi-Language Support: Supports various programming languages and platforms. Customizable Environments: Flexibility to customize the environment as needed. Version Control: Easy version management with rollback capabilities. Cost-Effective: Pay only for the resources used, no additional cost for Elastic Beanstalk. AWS Integration: Seamless integration with other AWS services. "
},
{
	"uri": "//localhost:1313/4-config-rds/4.1-updateiamrole/",
	"title": "Update IAM Role",
	"tags": [],
	"description": "",
	"content": "For our EC2 instances to be able to send session logs to the S3 bucket, we will need to update the IAM Role assigned to the EC2 instance by adding a policy that allows access to S3.\nUpdate IAM Role Go to IAM service management console Click Roles. In the search box, enter SSM. Click on the SSM-Role role. Click Attach policies. In the Search box enter S3. Click the policy AmazonS3FullAccess. Click Attach policy. In the production environment, we will grant stricter permissions to the specified S3 bucket. In the framework of this lab, we use the policy AmazonS3FullAccess for convenience.\nNext, we will proceed to create an S3 bucket to store session logs.\n"
},
{
	"uri": "//localhost:1313/1-introduce/1.2-pipeline/",
	"title": "CI/CD using AWS CodePipeline and AWS CodeBuild",
	"tags": [],
	"description": "",
	"content": "Overview of CI/CD CI/CD stands for Continuous Integration and Continuous Delivery (or Continuous Deployment), a set of practices used in modern software development to automate and streamline the process of building, testing, and deploying applications.\nContinuous Integration (CI): Involves automatically integrating code changes from multiple contributors into a shared repository several times a day. Each integration is verified by automated builds and tests, allowing teams to detect problems early.\nContinuous Delivery (CD): Extends CI by automatically deploying the application to a staging or production environment after successful builds and tests. This ensures that the software is always in a deployable state.\nAWS CodePipeline is a fully managed continuous integration and continuous delivery service that automates the steps required to release your software. With CodePipeline, you can define a series of stages, such as source, build, test, and deploy, which are triggered automatically when changes are detected in the source code repository.\nKey Features:\nAutomated Workflows: Automates the entire release process from code changes to deployment. Integration with AWS Services: Seamlessly integrates with other AWS services like CodeBuild, ECS, Lambda, and S3. Customizable Pipelines: Allows you to customize each stage of your pipeline, including using third-party tools or custom scripts. Parallel Execution: Supports parallel execution of actions to speed up the release process. Built-In Security: Offers encryption and integration with AWS Identity and Access Management (IAM) for secure access control. AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages ready for deployment. It eliminates the need to set up and manage your own build servers.\nKey Features:\nScalability: Automatically scales to handle multiple builds simultaneously, ensuring fast and reliable build times. Customizable Build Environment: Allows you to define your own build environments using Docker images, making it flexible for different programming languages and tools. Integration with CI/CD Pipelines: Easily integrates with AWS CodePipeline and other CI/CD tools to automate the build process as part of your deployment pipeline. Pay-As-You-Go Pricing: Charges only for the compute resources you use during the build process, making it cost-effective. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-clone-code/",
	"title": "Clone Code From Github",
	"tags": [],
	"description": "",
	"content": "Step-by-Step Access the folder where you want to store the code. Open Command Promt and type the command git clone https://github.com/DangLam2603/ebs-player-management-be.git After clone code successfully, open the following folder You will see the code structure to get start with the package code run on dotnet 6 runtime , so you will need to install the following SDK NET 6 SDK\n"
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.2-config-server-access/",
	"title": "Configure Server Access",
	"tags": [],
	"description": "",
	"content": "Overview In this part, we will use the modified IAM role for EC2 that we create in prerequiste ebs-ec2-webtier-role to allow Elastic Beanstalk access.\nChoose Create and Use the Servce role Enter new service role name Select ebs-ec2-webtier-role "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-create-iam-role/",
	"title": "Create IAM Role",
	"tags": [],
	"description": "",
	"content": "Create IAM Role For Elastic Beanstalk Navigate to AWS Console and search for IAM Select Role from left side bar and choose Create role Choose Trusted Service Select EC2 Add the following permision AWSElasticBeanstalkWebTier Enter Role name Choose Create Role "
},
{
	"uri": "//localhost:1313/4-config-rds/4.2-creates3bucket/",
	"title": "Create S3 Bucket",
	"tags": [],
	"description": "",
	"content": "In this step, we will create an S3 bucket to store session logs sent from EC2 instances.\nCreate S3 Bucket Access S3 service management console Click Create bucket. At the Create bucket page. In the Bucket name field, enter the bucket name lab-yourname-bucket-0001 In the Region section, select Region you are doing the current lab. The name of the S3 bucket must not be the same as all other S3 buckets in the system. You can substitute your name and enter a random number when generating the S3 bucket name.\nScroll down and click Create bucket. When we created the S3 bucket we did Block all public access so our EC2 instances won\u0026rsquo;t be able to connect to S3 via the internet. In the next step, we will configure the S3 Gateway Endpoint feature to allow EC2 instances to connect to the S3 bucket via the VPC\u0026rsquo;s internal network.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.3-download-aws-toolkit/",
	"title": "Install AWS ToolKit for Visual Studio",
	"tags": [],
	"description": "",
	"content": "Overview AWS ToolKit is an extension for Microsoft Visual Studio running on Microsoft Windows that makes it easier for developers to develop, debug, and deploy .NET applications using Amazon Web Services. You can choose 1 of following steps to install\nUsing Direct Download Link: you can follow this link to install which fit your .NET IDE. Visual Studio Visual Studio Code JetBrains Using Extention of Visual Studio 2022 IDE: Open Visual Studio 2022 =\u0026gt; Extention =\u0026gt; choose Online and search AWS ToolKit =\u0026gt; Install AWS ToolKit for Amazon Q "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "First, let go through some defination about our main AWS services Elastic Beanstalk and CodePipeline, CodeBuild to understand how continuous integration and continuous delivery/deployment works.\nContent Elastic Beanstalk CI/CD using CodePipelne, CodeBuild "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.4-add-inbound-rule/",
	"title": "Modify Inbound Rule",
	"tags": [],
	"description": "",
	"content": "Overview Locate to AWS Console, look for EC2 Service and select Security Group. Select and modify Your Security Group. Select Edit Inbound Rule Add Rule =\u0026gt; Select MSSQL type =\u0026gt; Save Rule In this workshop we will use MSSQL deploy to RDS Database, you can choose different database type by modify the port range to match with Database\u0026rsquo;s Port\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "",
	"content": "In this section, we will setup the necessary and important things to perform this workshop.\nContent Clone Code From GitHub Create IAM Role Download AWS ToolKit Add Inbound Rule "
},
{
	"uri": "//localhost:1313/4-config-rds/4.3-creategwes3/",
	"title": "Create S3 Gateway endpoint",
	"tags": [],
	"description": "",
	"content": " Go to VPC service management console Click Endpoints. Click Create endpoint. At the Create endpoint page. In the Name tag field, enter S3GW. In the Service Category section, click AWS services. In the search box enter S3, then select com.amazonaws.[region].s3 In the Services section, select com.amazonaws.[region].s3 with the Type of Gateway. In the VPC section, select Lab VPC. In the Route tables section, select both route tables. Scroll down, click Create endpoint. The next step is to configure Session Manager to store session logs to the S3 bucket we created.\n"
},
{
	"uri": "//localhost:1313/3-deploy-web-application/",
	"title": "Deploy Web Application With Elastic Beanstalk",
	"tags": [],
	"description": "",
	"content": "Once the prerequisites are set up, we\u0026rsquo;ll proceed with deploying our web API to the cloud using AWS Elastic Beanstalk. In this step, we\u0026rsquo;ll create an Elastic Beanstalk environment for deployment and connect through AWS ToolKit to upload our code from GitHub.\n"
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.3-setting-database-vpc/",
	"title": "Setting VPC and Database",
	"tags": [],
	"description": "",
	"content": "Overview Next, we\u0026rsquo;ll configure VPC and create new RDS database to host our SQL Server to cloud.\nSelect the exiting or Create new Vitural Private Cloud (VPC). In this demo, i\u0026rsquo;ll choose the default VPC. Choose the Avalibility Zone you want to run your application. Select your database subnets and enable database Modify the following:\nEngine : the engine of your database (in this workshop i\u0026rsquo;ll use SQL Server) Engine Version : version of database Instance class : instance type of database Storage : database storage Username : the username of database (key to connect to database) Password : the password of database (key to connect to database) Enter Next "
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.4-create-alb-asg/",
	"title": "Create Load Balancer and Auto Scaling Group",
	"tags": [],
	"description": "",
	"content": "Overview To further enhance the scalability, availability, and fault tolerance of the application, integrating an Auto Scaling Group (ASG) and a Load Balancer can be considered. These components are particularly beneficial for applications that require high availability and the ability to handle varying levels of traffic.\nChoose Default Security Group for your EC2 Setting Capacity for Auto Scaling Group Select Load Balancer Network Settings Select Load Balancer Type Select Instance Type "
},
{
	"uri": "//localhost:1313/4-config-rds/",
	"title": "Manage session logs",
	"tags": [],
	"description": "",
	"content": "With Session Manager, we can view the history of connections to instances through Session history. However, we have not seen the details of the commands used in a session.\nIn this section, we will proceed to create an S3 bucket and configure the session logs feature to see the details of the commands used in the session.\nContent: Update IAM Role Create S3 Bucket Create S3 Gateway endpoint Configure Session logs "
},
{
	"uri": "//localhost:1313/4-config-rds/4.4-configsessionlogs/",
	"title": "Monitor session logs",
	"tags": [],
	"description": "",
	"content": "Monitor session logs Access System Manager - Session Manager service management console Click the Preferences tab. Click Edit. Scroll down, at S3 logging, click Enable. Uncheck Allow only encrypted S3 buckets. Click Choose a bucket name from the list. Select the S3 bucket you created. Scroll down, click Save to save the configuration.\nAccess System Manager - Session Manager service management console\nClick Start session. Click Private Windows Instance. Click Start session. Type the command ipconfig. Type the command hostname. Click Terminate to exit the session, click Terminate again to confirm. Check Session logs in S3 Go to S3 service management console Click on the name of the S3 bucket we created for the lab. Click on the object name sessions log On the objects detail page, click Open. Object logs will be opened in a new tab in the browser. You can view the stored commands in session logs. "
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.5-create-environment-variable/",
	"title": "Add Environment Variable",
	"tags": [],
	"description": "",
	"content": "Overview The following step allow us to add environment variabale inside Elastic Beanstalk for security purpose\nEnabling CloudWatch Logs for Elastic Beanstalk is an essential step for monitoring and troubleshooting your application Set the following environment variables that configure the logging behavior. ASPNETCORE_ENVIRONMENT = Development (specific the dev enviroment on NET Core) ConnectionString__DefaultConnection = \u0026quot;Your Connection String\u0026quot; (add a connection to your RDS database) "
},
{
	"uri": "//localhost:1313/5-publish-api/",
	"title": "Port Forwarding",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding is a useful way to redirect network traffic from one IP address - Port to another IP address - Port. With Port Forwarding we can access an EC2 instance located in the private subnet from our workstation.\nWe will configure Port Forwarding for the RDP connection between our machine and Private Windows Instance located in the private subnet we created for this exercise.\nCreate IAM user with permission to connect SSM Go to IAM service management console Click Users , then click Add users. At the Add user page. In the User name field, enter Portfwd. Click on Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly.\nIn the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Save Access key ID and Secret access key information to perform AWS CLI configuration.\nInstall and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\nImplement Portforwarding Run the command below in Command Prompt on your machine to configure Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Windows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\nExample command: C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 If your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\nConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation. In the Computer section: enter localhost:9999. Return to the administration interface of the System Manager - Session Manager service. Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession. Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "//localhost:1313/6-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. Delete VPC Endpoints Go to VPC service management console Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. In the confirm box, enter delete.\nClick Delete to proceed with deleting endpoints. Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\nDelete VPC Go to VPC service management console\nClick Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC. In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n"
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.6-review-settings/",
	"title": "Review All Settings",
	"tags": [],
	"description": "",
	"content": "Overview One last step ahead , before hosting your web to cloud. Let\u0026rsquo;s review all the following,\nConfigure Environment Configure Service Access Setting Network, Datbase Config Traffic and Scaling Submit and Deploy "
},
{
	"uri": "//localhost:1313/3-deploy-web-application/3.7-result/",
	"title": "Test Your Application",
	"tags": [],
	"description": "",
	"content": "Overview In this part, we will take a look at our site and check for deployment working.\nDeploying applications on Elastic Beanstalk can sometimes take several minutes to start, especially for complex applications or environments with multiple configurations\nEnviroment launched then check the URL working. Deployment Success "
},
{
	"uri": "//localhost:1313/5-publish-api/5.1-publish-to-elasticbeanstalk/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/5-publish-api/5.2-demo-web-api-success/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]